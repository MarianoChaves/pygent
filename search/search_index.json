{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Pygent","text":"<p>Pygent is a minimal coding assistant that runs tasks inside an isolated Docker container whenever available. If Docker is not configured the commands run locally. This manual summarises the main commands and configuration options. See Configuration for a list of environment variables.</p> <p>The latest version of this guide is published online at marianochaves.github.io/pygent. See the Examples section for runnable scripts.</p> <p>See Getting Started for a quick tutorial or jump to the API Reference for details about the available classes.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install pygent\n</code></pre> <p>Python \u2265 3.9 is required. Docker is optional; install <code>pygent[docker]</code> to enable container execution. The default model is <code>gpt-4.1-mini</code>.</p>"},{"location":"#basic-usage","title":"Basic usage","text":"<p>Start an interactive session by running <code>pygent</code> in the terminal. Use the <code>--docker</code> option to run commands in a container (requires <code>pygent[docker]</code>); otherwise they execute locally. Use <code>/exit</code> to quit. Pass <code>--config path/to/pygent.toml</code> to load settings from a file. Alternatively run <code>pygent-ui</code> for a simple web interface (requires <code>pygent[ui]</code>).</p> <p>You can also use the Python API:</p> <pre><code>from pygent import Agent\nag = Agent()\nag.step(\"echo test\")\nag.runtime.cleanup()\n</code></pre> <p>Custom models are supported by implementing the <code>Model</code> protocol and passing the instance to <code>Agent</code>. They can also trigger tools by returning a message with <code>tool_calls</code> as shown in the <code>custom_model_with_tool.py</code> example. See the dedicated Custom Models page for extended examples and advanced usage.</p>"},{"location":"#development","title":"Development","text":"<p>Install optional dependencies with <code>pip install -e .[test,docs]</code> and run <code>pytest</code> to execute the tests. Use <code>mkdocs serve</code> to build this documentation locally.</p> <p>See the README file for more detailed information.</p>"},{"location":"api-reference/","title":"API Reference","text":"<p>This page describes the public classes and helpers provided by Pygent. Import everything from the package root unless noted otherwise.</p>"},{"location":"api-reference/#agent","title":"<code>Agent</code>","text":"<pre><code>from pygent import Agent\n</code></pre> <p><code>Agent</code> orchestrates the conversation with the selected model. Each instance owns a <code>Runtime</code> available as <code>agent.runtime</code>.</p>"},{"location":"api-reference/#methods","title":"Methods","text":"<ul> <li><code>step(user_msg: str) -&gt; pygent.openai_compat.Message</code> \u2013 add a message and run any tools returned by the model.</li> <li><code>run_interactive(use_docker: bool | None = None) -&gt; None</code> \u2013 start a terminal session.</li> <li><code>run_gui(use_docker: bool | None = None) -&gt; None</code> \u2013 launch the simple web interface.</li> <li><code>run_until_stop(user_msg: str, max_steps=20, ...) -&gt; None</code> \u2013 keep executing steps until the <code>stop</code> tool is called or a limit is reached.</li> </ul>"},{"location":"api-reference/#runtime","title":"<code>Runtime</code>","text":"<p><code>Runtime</code> executes commands either locally or in a Docker container.</p>"},{"location":"api-reference/#methods_1","title":"Methods","text":"<ul> <li><code>bash(cmd: str, timeout: int = 30) -&gt; str</code> \u2013 run a shell command and return its output.</li> <li><code>write_file(path: str, content: str) -&gt; str</code> \u2013 create or overwrite a UTF\u20118 file.</li> <li><code>read_file(path: str, binary: bool = False) -&gt; str</code> \u2013 read a file from the workspace.</li> <li><code>cleanup() -&gt; None</code> \u2013 destroy the temporary workspace and stop the container if one was used.</li> </ul>"},{"location":"api-reference/#builtin-tools","title":"Built\u2011in tools","text":"<p>These tools are registered automatically:</p> <ul> <li>bash \u2013 run a command through <code>Runtime.bash</code>.</li> <li>write_file \u2013 create files via <code>Runtime.write_file</code>.</li> <li>delegate_task \u2013 start a background agent.</li> <li>delegate_persona_task \u2013 like <code>delegate_task</code> but lets you pick the persona.</li> <li>list_personas \u2013 return the available personas for delegation.</li> <li>task_status \u2013 check the status of a delegated task.</li> <li>collect_file \u2013 copy a file from a delegated task into the current workspace.</li> <li>download_file \u2013 read a file using <code>Runtime.read_file</code>.</li> <li>continue \u2013 request user input when running autonomously.</li> <li>stop \u2013 stop the autonomous loop.</li> </ul> <p>Custom tools can be registered programmatically:</p> <pre><code>from pygent import register_tool\n\ndef hello(rt, name: str) -&gt; str:\n    return f\"Hello {name}!\"\n\nregister_tool(\n    \"hello\",\n    \"Greet the user\",\n    {\"type\": \"object\", \"properties\": {\"name\": {\"type\": \"string\"}}, \"required\": [\"name\"]},\n    hello,\n)\n</code></pre>"},{"location":"api-reference/#taskmanager","title":"<code>TaskManager</code>","text":"<pre><code>from pygent import TaskManager, Runtime\n</code></pre> <p><code>TaskManager</code> launches separate agents asynchronously and tracks them. Pass a <code>Runtime</code> instance when starting a task so files can be copied into the sub\u2011agent's workspace.</p>"},{"location":"api-reference/#personas","title":"Personas","text":"<p>Agents can adopt different personas. The defaults come from the <code>PYGENT_PERSONA_NAME</code> and <code>PYGENT_PERSONA</code> environment variables. Delegated agent personas can be configured via <code>PYGENT_TASK_PERSONAS_JSON</code>. The <code>list_personas</code> tool returns all available options.</p>"},{"location":"api-reference/#custom-prompts","title":"Custom prompts","text":"<p>Provide a <code>Persona</code> object to the <code>Agent</code> constructor to override the system prompt:</p> <pre><code>from pygent import Agent, Persona\n\nag = Agent(persona=Persona(\"Helper\", \"a friendly bot\"))\n</code></pre>"},{"location":"api-reference/#custom-models","title":"Custom models","text":"<p><code>Agent</code> relies on an object implementing the <code>Model</code> protocol. The default <code>OpenAIModel</code> calls an OpenAI\u2011compatible API, but any backend can be plugged in. Custom models may return tool calls by filling the <code>tool_calls</code> attribute of the returned message.</p>"},{"location":"configuration/","title":"Configuration","text":"<p>This page summarises the environment variables that control Pygent.  They can be exported in your shell or set via a <code>.env</code> file before running the CLI.</p> Variable Description Default <code>OPENAI_API_KEY</code> API key for OpenAI or any compatible service. \u2013 <code>OPENAI_BASE_URL</code> Base URL for the API endpoint. <code>https://api.openai.com/v1</code> <code>PYGENT_MODEL</code> Model name used for requests. <code>gpt-4.1-mini</code> <code>PYGENT_IMAGE</code> Docker image used for sandboxed execution. <code>python:3.12-slim</code> <code>PYGENT_USE_DOCKER</code> Set to <code>0</code> to run commands locally. Otherwise the runtime will try to use Docker if available. auto <code>PYGENT_MAX_TASKS</code> Maximum number of delegated tasks that can run concurrently. <code>3</code> <code>PYGENT_STEP_TIMEOUT</code> Default time limit in seconds for each step when running delegated tasks. \u2013 <code>PYGENT_TASK_TIMEOUT</code> Default overall time limit in seconds for delegated tasks. \u2013 <code>PYGENT_PERSONA_NAME</code> Name of the main agent persona. <code>Pygent</code> <code>PYGENT_PERSONA</code> Description of the main agent persona. \"a sandboxed coding assistant.\" <code>PYGENT_TASK_PERSONAS</code> List of personas for delegated agents separated by <code>os.pathsep</code>. \u2013 <code>PYGENT_TASK_PERSONAS_JSON</code> JSON array of persona objects with name and description for delegated agents. Overrides <code>PYGENT_TASK_PERSONAS</code> if set. \u2013 <code>PYGENT_INIT_FILES</code> List of files or directories copied into the workspace at startup, separated by <code>os.pathsep</code>. \u2013 <p>Instead of setting environment variables you can create a <code>pygent.toml</code> file in the current directory or in your home folder. Values defined there are loaded at startup if the corresponding variables are unset. Example:</p> <pre><code>persona_name = \"FriendlyBot\"\npersona = \"a friendly bot\"\n\n[[task_personas]]\nname = \"tester\"\ndescription = \"runs tests\"\n\n[[task_personas]]\nname = \"developer\"\ndescription = \"implements features\"\n\ninitial_files = [\"bootstrap.py\"]\n</code></pre> <p>The keys map to the environment variables of the same name.</p> <p>You can also specify a configuration file explicitly when launching the CLI:</p> <pre><code>pygent --config path/to/pygent.toml\n</code></pre> <p>A practical example is included in <code>examples/sample_config.toml</code> together with the script <code>config_file_example.py</code>, which delegates a testing task:</p> <pre><code>python examples/config_file_example.py\n</code></pre> <p>See Getting Started for installation instructions and the API Reference for details about the available classes.</p>"},{"location":"custom-models/","title":"Custom Models","text":"<p>Pygent allows plugging in any model backend as long as it implements the <code>Model</code> protocol. This page collects extended examples showing how to build your own models, use the <code>openai_compat</code> helpers and return tool calls.</p>"},{"location":"custom-models/#echo-model","title":"Echo model","text":"<p>A trivial example that simply repeats the last user message. The implementation returns an <code>openai_compat.Message</code> instance.</p> <pre><code>from pygent import Agent, openai_compat\n\nclass EchoModel:\n    def chat(self, messages, model, tools):\n        last = messages[-1][\"content\"]\n        return openai_compat.Message(role=\"assistant\", content=f\"Echo: {last}\")\n\nag = Agent(model=EchoModel())\nag.step(\"test\")\n</code></pre>"},{"location":"custom-models/#calling-a-remote-api-with-openai_compat","title":"Calling a remote API with <code>openai_compat</code>","text":"<p>The <code>openai_compat</code> module ships a lightweight client mirroring the official OpenAI interface. You can use it to talk to any compatible endpoint.</p> <pre><code>from pygent import Agent, openai_compat\n\nclass HTTPModel:\n    def chat(self, messages, model, tools):\n        resp = openai_compat.chat.completions.create(\n            model=model,\n            messages=messages,\n            tools=tools,\n            tool_choice=\"auto\",\n        )\n        return resp.choices[0].message\n\nag = Agent(model=HTTPModel())\nag.step(\"who am I?\")\n</code></pre> <p>Set <code>OPENAI_BASE_URL</code> and <code>OPENAI_API_KEY</code> to target a different provider if needed.</p>"},{"location":"custom-models/#returning-tool-calls","title":"Returning tool calls","text":"<p>Custom models may trigger tools by returning a message with the <code>tool_calls</code> attribute populated. The next example runs the last user message as a <code>bash</code> command.</p> <pre><code>import json\nfrom pygent import Agent, openai_compat\n\nclass BashModel:\n    def chat(self, messages, model, tools):\n        cmd = messages[-1][\"content\"]\n        call = openai_compat.ToolCall(\n            id=\"1\",\n            type=\"function\",\n            function=openai_compat.ToolCallFunction(\n                name=\"bash\",\n                arguments=json.dumps({\"cmd\": cmd}),\n            ),\n        )\n        return openai_compat.Message(role=\"assistant\", content=None, tool_calls=[call])\n\nag = Agent(model=BashModel())\nag.step(\"echo 'hi from tool'\")\n</code></pre>"},{"location":"custom-models/#global-custom-model","title":"Global custom model","text":"<p>Use <code>set_custom_model</code> to apply a model to all new agents and delegated tasks:</p> <pre><code>from pygent import Agent\nfrom pygent.models import set_custom_model\n\nset_custom_model(EchoModel())\nag = Agent()\nag.step(\"hello\")\nset_custom_model(None)\n</code></pre>"},{"location":"custom-models/#delegating-tasks-from-a-custom-model","title":"Delegating tasks from a custom model","text":"<p>Models can call the <code>delegate_task</code> tool to start a background agent. This example delegates once and then stops.</p> <pre><code>import json\nfrom pygent import Agent, openai_compat\n\nclass DelegateModel:\n    def __init__(self):\n        self.first = True\n\n    def chat(self, messages, model, tools):\n        if self.first:\n            self.first = False\n            return openai_compat.Message(\n                role=\"assistant\",\n                content=None,\n                tool_calls=[\n                    openai_compat.ToolCall(\n                        id=\"1\",\n                        type=\"function\",\n                        function=openai_compat.ToolCallFunction(\n                            name=\"delegate_task\",\n                            arguments=json.dumps({\"prompt\": \"noop\"}),\n                        ),\n                    )\n                ],\n            )\n        return openai_compat.Message(role=\"assistant\", content=None, tool_calls=[\n            openai_compat.ToolCall(\n                id=\"2\",\n                type=\"function\",\n                function=openai_compat.ToolCallFunction(name=\"stop\", arguments=\"{}\"),\n            )\n        ])\n\nag = Agent(model=DelegateModel())\nag.run_until_stop(\"begin\", max_steps=2)\n</code></pre>"},{"location":"custom-models/#custom-tool-and-external-model-in-a-delegated-task","title":"Custom tool and external model in a delegated task","text":"<p>This scenario combines several features: defining a new tool, using an OpenAI-compatible service via <code>openai_compat</code> and delegating work to a background agent.</p> <pre><code>import json\nimport time\nfrom pygent import Agent, TaskManager, register_tool, openai_compat\n\ndef shout(rt, text: str) -&gt; str:\n    return text.upper()\n\nregister_tool(\n    \"shout\",\n    \"Uppercase some text\",\n    {\"type\": \"object\", \"properties\": {\"text\": {\"type\": \"string\"}}, \"required\": [\"text\"]},\n    shout,\n)\n\nclass HTTPModel:\n    def chat(self, messages, model, tools):\n        resp = openai_compat.chat.completions.create(\n            model=model, messages=messages, tools=tools, tool_choice=\"auto\"\n        )\n        return resp.choices[0].message\n\nclass DelegatingModel:\n    def __init__(self):\n        self.done = False\n\n    def chat(self, messages, model, tools):\n        if not self.done:\n            self.done = True\n            return openai_compat.Message(\n                role=\"assistant\",\n                content=None,\n                tool_calls=[\n                    openai_compat.ToolCall(\n                        id=\"1\",\n                        type=\"function\",\n                        function=openai_compat.ToolCallFunction(\n                            name=\"delegate_task\",\n                            arguments=json.dumps({\"prompt\": \"shout text='hi'\\nstop\"}),\n                        ),\n                    )\n                ],\n            )\n        return openai_compat.Message(role=\"assistant\", content=\"delegated\")\n\nmanager = TaskManager(agent_factory=lambda p=None: Agent(model=HTTPModel(), persona=p))\nmain = Agent(model=DelegatingModel())\n\ntask_id = manager.start_task(\"begin\", main.runtime)\nwhile manager.status(task_id) == \"running\":\n    time.sleep(1)\nprint(\"Status:\", manager.status(task_id))\n</code></pre> <p>These snippets demonstrate different ways of integrating custom logic with Pygent. See the examples directory for the full source code.</p>"},{"location":"examples/","title":"Examples","text":"<p>This page collects small scripts demonstrating different aspects of Pygent. Each link points to the source file on GitHub.</p> <ul> <li>api_example.py \u2013 minimal use of the :class:<code>~pygent.agent.Agent</code> API.</li> <li>runtime_example.py \u2013 using the :class:<code>~pygent.runtime.Runtime</code> class directly.</li> <li>write_file_demo.py \u2013 calling the built-in tools from Python code.</li> <li>custom_model.py \u2013 implementing a simple custom model.</li> <li>custom_model_with_tool.py \u2013 custom model issuing tool calls.</li> <li>custom_tool.py \u2013 registering a custom tool.</li> <li>delegate_task_example.py \u2013 delegating work to a background agent.</li> <li>config_file_example.py \u2013 loading a config file and delegating a testing agent.</li> <li>delegate_external_tool.py \u2013 new tool using an external model service inside a delegated task.</li> </ul> <p>See the Custom Models page for a walkthrough of building your own models.</p> <p>See the Custom Models page for a walkthrough of building your own models.</p> <p>Run these with <code>python &lt;script&gt;</code> from the project root. They expect the environment variables described in the Configuration page.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Pygent is a minimalist coding assistant that runs shell commands inside a sandboxed environment. By default a Docker container is used, but if Docker is unavailable the commands run locally instead. This page shows how to install the package and gives a few examples covering the main features.</p>"},{"location":"getting-started/#installation","title":"Installation","text":"<p>Install from source in editable mode so the CLI and Python modules are available. Include the optional extras to enable Docker support and the web UI:</p> <pre><code>pip install pygent[docker,ui]\n</code></pre> <p>Python 3.9 or newer is required. If Docker is not installed omit the <code>[docker]</code> extras and commands will run on the host system.</p>"},{"location":"getting-started/#interactive-session","title":"Interactive session","text":"<p>Start an interactive session by running <code>pygent</code> in a terminal. Use the <code>--docker</code> flag to force container execution or <code>--no-docker</code> to run locally.</p> <pre><code>$ pygent --docker\nvc&gt; echo \"Hello\"\n</code></pre> <p>Each message is executed in the sandbox and the output printed. Use <code>/exit</code> to leave the session. You can also launch a simple web interface with <code>pygent-ui</code> (requires the <code>ui</code> extra).</p>"},{"location":"getting-started/#tool-usage","title":"Tool usage","text":"<p>During the conversation the assistant can call two built-in tools: <code>bash</code> to run shell commands and <code>write_file</code> to create files inside the workspace. For example:</p> <pre><code>vc&gt; write_file path=\"hello.txt\" content=\"Hello from Pygent\"\nvc&gt; bash cmd=\"cat hello.txt\"\n</code></pre>"},{"location":"getting-started/#using-the-api","title":"Using the API","text":"<p>The same functionality is accessible programmatically via the <code>Agent</code> class:</p> <pre><code>from pygent import Agent\n\nag = Agent()\nag.step(\"echo 'Hello World'\")\nag.runtime.cleanup()\n</code></pre> <p>See api_example.py for a complete script. Additional examples show how to implement a custom model and how to interact with the <code>Runtime</code> class directly.</p>"},{"location":"getting-started/#configuration","title":"Configuration","text":"<p>Pygent communicates with the model through an OpenAI\u2011compatible API. Export your API key before running the assistant. A full list of environment variables is available in the Configuration page.</p> <p>For full control you may pass a custom model implementation to <code>Agent</code>. The file custom_model.py contains a minimal echo model example. A dedicated Custom Models page expands on this topic with additional scenarios.</p>"},{"location":"getting-started/#additional-examples","title":"Additional examples","text":"<p>Several scripts in the <code>examples/</code> directory showcase different parts of the package (see the dedicated Examples page):</p> <ul> <li>api_example.py \u2013 minimal use of the :class:<code>~pygent.agent.Agent</code> API.</li> <li>runtime_example.py \u2013 running commands through the   :class:<code>~pygent.runtime.Runtime</code> class directly.</li> <li>write_file_demo.py \u2013 calling the built-in tools from Python code.</li> <li>custom_model.py \u2013 plugging in a custom model.</li> </ul> <p>Below is the custom model snippet for reference:</p> <pre><code>from pygent import Agent, openai_compat\n\nclass EchoModel:\n    def chat(self, messages, model, tools):\n        last = messages[-1][\"content\"]\n        return openai_compat.Message(role=\"assistant\", content=f\"Echo: {last}\")\n\nag = Agent(model=EchoModel())\nag.step(\"test\")\nag.runtime.cleanup()\n</code></pre> <p>Custom models can also issue tool calls. The following model runs the last user message as a <code>bash</code> command:</p> <pre><code>import json\nfrom pygent import Agent, openai_compat\n\n\nclass BashModel:\n    def chat(self, messages, model, tools):\n        cmd = messages[-1][\"content\"]\n        call = openai_compat.ToolCall(\n            id=\"1\",\n            type=\"function\",\n            function=openai_compat.ToolCallFunction(\n                name=\"bash\",\n                arguments=json.dumps({\"cmd\": cmd}),\n            ),\n        )\n        return openai_compat.Message(role=\"assistant\", content=None, tool_calls=[call])\n\n\nag = Agent(model=BashModel())\nag.step(\"echo hi\")\nag.runtime.cleanup()\n</code></pre> <p>See the API reference for the complete list of classes and configuration options.</p>"}]}